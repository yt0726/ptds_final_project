---
title: "my-vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{my-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup,include=FALSE}
library(Spotify)
library(vembedr)

```


This vignette provides more information of this package. This package contains 4 functions. You could get the details of each function in the following context.        

The package depends on functions that are made available from other packages:
*dplyr*, *plotly*, *lsa*, *shinydashboard*, *shiny*, *shinythemes*, *shinyWidgets*, *fresh*, *DT*.    

# Spotify Application   

**Function: Spotify::Spotify_gui**

This function is to run the application. To run the application, you could run it directly to start-up the program. You would see the pop-up window of the application, then you could input your preference following the instructions on the first page `Introduction`. When you only run this application, you do not need to have any data. There is a data set obtained from Spotify containing 106,943 observation (songs).    

*Running example*   
```{r,eval=FALSE}
Spotify::Spotify_gui()
```

Here is the screencast for running APP:    

```{r,echo=FALSE, out.width="100%"}
embed_url("https://youtu.be/81jgy23Xsr0")
```


# Data set included in Package      

**Function: Spotify::Spotify_dataset**    

This package contains one data set which is also the data source for running the application shown above. This data set is from Spotify, and it contains 20 columns:

* Track_id: The Spotify ID for the track    
* Artists: The artists' names who performed the track. If there is more than one artist, they are separated by a.      
* Album_name: The album name in which the track appears.    
* Track_name: Name of the track.
* Popularity: The popularity of a track is a value between 0 and 10, with 10 being the most popular. The popularity is calculated by algorithm and is based, in the most part, on the total number of plays the track has had and how recent those plays are. Generally speaking, songs that are being played a lot now will have a higher popularity than songs that were played a lot in the past. Duplicate tracks (e.g. the same track from a single and an album) are rated independently. Artist and album popularity is derived mathematically from track popularity.    
* Duration_ms: The track length in milliseconds.    
* Explicit: Whether or not the track has explicit lyrics (true = yes it does; false = no it does not OR unknown).    
* Danceability: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 10 is most danceable.    
* Energy: Energy is a measure from 0.0 to 10 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale.   
* Key: The key the track is in. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on.    
* Loudness: The overall loudness of a track in decibels (dB).   
* Mode: Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.   
* Speechiness: Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 10 the attribute value. Values above 6.6 describe tracks that are probably made entirely of spoken words. Values between 3.3 and 6.6 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 3.3 most likely represent music and other non-speech-like tracks.    
* Acousticness: A confidence measure from 0.0 to 10 of whether the track is acoustic. 10 represents high confidence the track is acoustic.    
* Instrumentalness: Predicts whether a track contains no vocals. "Ooh" and "aah" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly "vocal". The closer the instrumentalness value is to 10, the greater likelihood the track contains no vocal content.   
* Liveness: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 8 provides strong likelihood that the track is live.      
* Valence: A measure from 0 to 10 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).       
* Tempo: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration       
* Time_signature: An estimated time signature. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).     
* Track_genre: The genre in which the track belongs.     

You could fine-tune your preference for the features from column 5 to column 20 when you run the application, and even the scoring function and similarity function which will be explained in the following.        

**10 examples of the data**    
```{r}
knitr::kable(Spotify::Spotify_dataset[1:10,])
```
    
         
# Scoring Function     

**Function: Spotify::Spotify_scoring**   

If you want to input a new data set to obtain your specific list, you might want to run this function individually. Thus, to run this function, you should have a data set as one of the input variables, and you also need to input the music genres you prefer, your five favorite features and their corresponding levels, since you do not input your selection via the application.    

When working with the input variables you must:   

* input the music genres, features and their corresponding levels you prefer.   
* variables' format should be characters.     

Regarding the output, you will get a list which contains the data as following:     

* result: This is the result data frame calculated based on the input of your features and levels selection. There is top 10 music that are the most matched with the number of levels of features you enter.      
* user_genres: return to your input music genres. It is characters.    
* user_features: return to your input five features. It is characters.   
* user_level: return to your input five levels, which are correspond to the features. It is characters. 

Here, it is the example:   
```{r scoring, echo=FALSE}
example <- Spotify_scoring(genres="Funk",
                features=c("Danceability","Energy","Loudness","Speechiness","Liveness"),
                levels = c(9,8,5,4,7))
knitr::kable(example$result)
```

# Similarity Function 

**Function: Spotify::Spotify_similarity**  

This function consider using the basic recommendation engine algorithm. Create similarity scores for songs by calculating Cosine similarity between selected features and levels and the those of songs in data base, then obtain a new recommended songs list which have largest similarity with the selected filters.    

The formula of the Cosine similarity is as follows:   
$$sim(A,B)=cos(A,B)=\frac{A\cdot B}{||A||\cdot||B||}=\frac{\sum_{i = 1}^{n} A_{i}B_{i}}{\sqrt{\sum_{i = 1}^{n} A_{i}^2}\sqrt{\sum_{i = 1}^{n} B_{i}^2}}$$
Thus, it does the same thing as the previous `Spotify_scoring` function but use different algorithm. Also, you can only run this function with new filters. Below, you can see another example with same input variables as above but obtain a different result list. Also, please ensure the input variables as characters.        

```{r similarity,echo=FALSE}
example_2 <- Spotify_similarity(genres = "Funk",
features=c("Danceability","Energy","Loudness","Speechiness","Liveness"),
levels = c(9,8,5,4,7))

knitr::kable(example_2$result)
```



# Radar plot   

**Function: Spotify::radar_plot** 

To run this function individually, you are supposed to input a list object as the input variable. The list object should be in the same structure as the output of `Spotify_scoring` or `Spotify_similarity` function. Which means, it contains a data frame result, user_genres, user_features, user_level.

* data frame result: should have at least one row except for the header.       
* In this case, in the plot output, you could only see two layers. One is the layer for the result list, another is for your original input, the features and levels you prefer.      
* Meantime, you need input the `rank` variable which indicates the song you want to plot. For example, if you want to plot the first song, you would input rank=1, if you want to plot the second, then input rank =2, and so on, and the values of their features' levels would be captured. The example below only plots one songs and compared with the selections. Check example as following:    

```{r radarplot, echo = FALSE, message=FALSE,warning=FALSE}
radar_plot(example,rank = 1)
```
